"""
Data processing utilities for dental health research.
Includes functions for data conversion, cleaning, and preprocessing.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, Union
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def convert_sas_to_parquet(sas_file_path: Union[str, Path], 
                          parquet_file_path: Union[str, Path]) -> bool:
    """
    Chuyá»ƒn Ä‘á»•i tá»‡p dá»¯ liá»‡u tá»« Ä‘á»‹nh dáº¡ng SAS (.sas7bdat) sang Ä‘á»‹nh dáº¡ng Parquet (.parquet).

    Args:
        sas_file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n tá»‡p SAS Ä‘áº§u vÃ o
        parquet_file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n tá»‡p Parquet Ä‘áº§u ra

    Returns:
        bool: True náº¿u chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng, False náº¿u cÃ³ lá»—i
    """
    logger.info("ðŸ”„ Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i...")
    
    # Kiá»ƒm tra xem tá»‡p SAS cÃ³ tá»“n táº¡i khÃ´ng
    if not Path(sas_file_path).exists():
        logger.error(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y tá»‡p Ä‘áº§u vÃ o '{sas_file_path}'")
        return False

    try:
        # Äá»c tá»‡p SAS vÃ o má»™t pandas DataFrame
        logger.info(f"ðŸ“„ Äang Ä‘á»c tá»‡p SAS: '{sas_file_path}'...")
        df = pd.read_sas(sas_file_path, format='sas7bdat', encoding='ISO-8859-1')
        logger.info(f"âœ… Äá»c tá»‡p SAS thÃ nh cÃ´ng. Dá»¯ liá»‡u cÃ³ {df.shape[0]} dÃ²ng vÃ  {df.shape[1]} cá»™t.")

        # Ghi DataFrame ra tá»‡p Parquet
        logger.info(f"âœï¸ Äang ghi ra tá»‡p Parquet: '{parquet_file_path}'...")
        df.to_parquet(parquet_file_path, engine='pyarrow')
        logger.info(f"âœ… Chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng! Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i '{parquet_file_path}'")
        return True

    except Exception as e:
        logger.error(f"âŒ ÄÃ£ xáº£y ra lá»—i trong quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i: {e}")
        return False


def load_brfss_data(file_path: Union[str, Path], 
                   file_format: str = 'parquet') -> Optional[pd.DataFrame]:
    """
    Táº£i dá»¯ liá»‡u BRFSS tá»« file.

    Args:
        file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file dá»¯ liá»‡u
        file_format: Äá»‹nh dáº¡ng file ('parquet', 'sas', 'csv')

    Returns:
        pd.DataFrame hoáº·c None náº¿u cÃ³ lá»—i
    """
    try:
        if file_format.lower() == 'parquet':
            df = pd.read_parquet(file_path)
        elif file_format.lower() == 'sas':
            df = pd.read_sas(file_path, format='sas7bdat', encoding='ISO-8859-1')
        elif file_format.lower() == 'csv':
            df = pd.read_csv(file_path)
        else:
            raise ValueError(f"Äá»‹nh dáº¡ng file khÃ´ng Ä‘Æ°á»£c há»— trá»£: {file_format}")
        
        logger.info(f"âœ… Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng: {df.shape[0]} dÃ²ng, {df.shape[1]} cá»™t")
        return df
    
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi táº£i dá»¯ liá»‡u: {e}")
        return None


def get_data_info(df: pd.DataFrame) -> dict:
    """
    Láº¥y thÃ´ng tin tá»•ng quan vá» dataset.

    Args:
        df: DataFrame cáº§n phÃ¢n tÃ­ch

    Returns:
        dict: ThÃ´ng tin vá» dataset
    """
    info = {
        'shape': df.shape,
        'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024**2,
        'missing_percentage': (df.isnull().sum() / len(df) * 100).round(2),
        'dtypes': df.dtypes.value_counts(),
        'numeric_columns': df.select_dtypes(include=[np.number]).columns.tolist(),
        'categorical_columns': df.select_dtypes(include=['object', 'category']).columns.tolist()
    }
    return info


def clean_brfss_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    LÃ m sáº¡ch dá»¯ liá»‡u BRFSS cÆ¡ báº£n.

    Args:
        df: DataFrame gá»‘c

    Returns:
        pd.DataFrame: DataFrame Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch
    """
    df_clean = df.copy()
    
    # Log thÃ´ng tin ban Ä‘áº§u
    logger.info(f"Dá»¯ liá»‡u ban Ä‘áº§u: {df_clean.shape[0]} dÃ²ng, {df_clean.shape[1]} cá»™t")
    
    # Xá»­ lÃ½ missing values cÆ¡ báº£n
    initial_missing = df_clean.isnull().sum().sum()
    logger.info(f"Tá»•ng sá»‘ missing values: {initial_missing}")
    
    # CÃ³ thá»ƒ thÃªm cÃ¡c bÆ°á»›c lÃ m sáº¡ch cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y
    
    logger.info(f"Dá»¯ liá»‡u sau khi lÃ m sáº¡ch: {df_clean.shape[0]} dÃ²ng, {df_clean.shape[1]} cá»™t")
    return df_clean


if __name__ == '__main__':
    # VÃ­ dá»¥ sá»­ dá»¥ng
    input_sas_file = 'data/llcp2022.sas7bdat'
    output_parquet_file = 'data/llcp2022_converted.parquet'
    
    # Thá»±c hiá»‡n chuyá»ƒn Ä‘á»•i
    success = convert_sas_to_parquet(input_sas_file, output_parquet_file)
    
    if success:
        # Táº£i vÃ  kiá»ƒm tra dá»¯ liá»‡u
        df = load_brfss_data(output_parquet_file)
        if df is not None:
            info = get_data_info(df)
            print(f"ThÃ´ng tin dataset: {info}")
